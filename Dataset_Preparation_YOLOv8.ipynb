{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immport\n",
    "from xml.dom import minidom\n",
    "import bs4 as bs\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPascal2YOLOv8(filePath):\n",
    "\n",
    "    class_mapping = {\n",
    "        \"D00\": 0,\n",
    "        \"D10\": 1,\n",
    "        \"D20\": 2,\n",
    "        \"D40\": 3,\n",
    "        \"D01\": 4,\n",
    "        \"D11\": 5,\n",
    "        \"D43\": 6,\n",
    "        \"D44\": 7,\n",
    "        \"D50\": 8\n",
    "    }\n",
    "    \n",
    "    # reading content\n",
    "    file = open(filePath, \"r\")\n",
    "    contents = file.read()\n",
    "\n",
    "    # parsing\n",
    "    soup = bs.BeautifulSoup(contents, 'xml')\n",
    "    image_size = soup.find_all(\"size\")[0]\n",
    "    image_width = int(image_size.find_all(\"width\")[0].get_text())\n",
    "    image_height = int(image_size.find_all(\"height\")[0].get_text())\n",
    "    # print(\"w,h :\", image_width, image_height)\n",
    "\n",
    "    # Process Bounding Box\n",
    "    objects = soup.find_all(\"object\")\n",
    "\n",
    "    # Placeholder\n",
    "    bounding_box_list = []\n",
    "    class_list = []\n",
    "\n",
    "    for object in objects:\n",
    "        \n",
    "        # Object Class\n",
    "        _class = object.find_all(\"name\")[0].get_text()\n",
    "        \n",
    "        # Map the class to int number, if not defined > 10\n",
    "        _class = class_mapping.get(_class, 10)\n",
    "        class_list.append(_class)\n",
    "        \n",
    "        # Object Bounding Box\n",
    "        _xmin = float(object.find_all(\"xmin\")[0].get_text())\n",
    "        _ymin = float(object.find_all(\"ymin\")[0].get_text())\n",
    "        _xmax = float(object.find_all(\"xmax\")[0].get_text())\n",
    "        _ymax = float(object.find_all(\"ymax\")[0].get_text())\n",
    "\n",
    "        # Convert to YOLOv8 Annotation\n",
    "        # class x_center y_center width height\n",
    "        w = (_xmax - _xmin)\n",
    "        h = (_ymax - _ymin)\n",
    "        cx = _xmin + (w/2)\n",
    "        cy = _ymin + (h/2)\n",
    "\n",
    "        # Normalize\n",
    "        w = round((w / image_width), 4)\n",
    "        h = round((h / image_height), 4)\n",
    "        cx = round((cx / image_width), 4)\n",
    "        cy = round((cy / image_height), 4)\n",
    "\n",
    "        _bbox = [cx, cy, w, h]\n",
    "\n",
    "        # print(_class, cx, cy, w, h)\n",
    "\n",
    "        bounding_box_list.append(_bbox)\n",
    "\n",
    "    # Get the filename\n",
    "    outputFilename = os.path.split(filePath)[1]\n",
    "    outputFilename = outputFilename.replace(\".xml\", \".txt\")\n",
    "\n",
    "    # Output Path\n",
    "    outputDir = Path(filePath).parents[2]\n",
    "    outputDir = outputDir / \"labels\"\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "\n",
    "    # Final output path\n",
    "    outputPath = outputDir / outputFilename\n",
    "    # print(outputPath)\n",
    "\n",
    "    # Write to .txt file\n",
    "    with open(outputPath, 'w') as f:\n",
    "        for i in range(len(class_list)):\n",
    "\n",
    "            # Filter the class, drop unused class\n",
    "            # 0: D00 > Longitudinal Crack\n",
    "            # 1: D10 > Transverse Crack\n",
    "            # 2: D20 > Alligator Crack\n",
    "            # 3: D40 > Potholes\n",
    "            \n",
    "            if class_list[i] < 4:\n",
    "                anno = str(class_list[i]) + \" \" +  str(bounding_box_list[i][0]) + \" \" +  str(bounding_box_list[i][1]) + \" \" +  str(bounding_box_list[i][2]) + \" \" +  str(bounding_box_list[i][3]) + \"\\n\"\n",
    "                f.write(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022\n",
      "The directory 'd:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022' is valid and exists.\n",
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/Japan/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10506/10506 [00:43<00:00, 241.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/India/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7706/7706 [00:58<00:00, 132.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/China_Drone/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:18<00:00, 128.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/China_MotorBike/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1977/1977 [00:17<00:00, 110.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/Czech/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/Norway/Norway/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryDir: d:\\code\\CS632_roaddamagedetection\\dataset\\RDD2022/RDD2022_all_countries/United_States/United_States/train/annotations/xmls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset Root Directory\n",
    "# ROOTDIR = \"/dataset/RDD2022/\"\n",
    "current_dir = os.getcwd()\n",
    "ROOTDIR = os.path.join(current_dir, \"dataset\", \"RDD2022\")\n",
    "print(ROOTDIR)\n",
    "\n",
    "if os.path.exists(ROOTDIR) and os.path.isdir(ROOTDIR):\n",
    "    print(f\"The directory '{ROOTDIR}' is valid and exists.\")\n",
    "else:\n",
    "    print(f\"The directory '{ROOTDIR}' is not valid or does not exist.\")\n",
    "\n",
    "# Base Directory\n",
    "CountryListDir = [\"/RDD2022_all_countries/Japan/train/annotations/xmls\",\n",
    "                  \"/RDD2022_all_countries/India/train/annotations/xmls\",\n",
    "                  \"/RDD2022_all_countries/China_Drone/train/annotations/xmls\",\n",
    "                  \"/RDD2022_all_countries/China_MotorBike/train/annotations/xmls\",\n",
    "                  \"/RDD2022_all_countries/Czech/train/annotations/xmls\",\n",
    "                  \"/RDD2022_all_countries/Norway/Norway/train/annotations/xmls\",\n",
    "                  \"/RDD2022_all_countries/United_States/United_States/train/annotations/xmls\",\n",
    "]\n",
    "\n",
    "for CountryDir in CountryListDir:\n",
    "    \n",
    "    CountryDir = ROOTDIR + CountryDir\n",
    "    print(\"CountryDir:\",CountryDir)\n",
    "    fileList = sorted(glob.glob(CountryDir + \"/*.xml\"))\n",
    "\n",
    "    # Processing all the annotation\n",
    "    for file in tqdm(fileList):\n",
    "        convertPascal2YOLOv8(file)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CopyDatasetSplit(baseDir):\n",
    "    \n",
    "    # Split the training data to train and validation data due to lack of annotation on test data\n",
    "    # Seed\n",
    "    random.seed(1337)\n",
    "    \n",
    "    # Output Directory\n",
    "    # !!! Change this to your clone folder\n",
    "    baseOutputDir = \"D:/code/CS632_roaddamagedetection/dataset/rddJapanIndiaChinaFiltered/\"\n",
    "    countryName = Path(baseDir).parents[0]\n",
    "    countryName = os.path.split(countryName)[1]\n",
    "\n",
    "    baseImageDir = baseDir + \"images/\"\n",
    "    baseAnnotDir = baseDir + \"labels/\"\n",
    "\n",
    "    image_list_all = sorted(glob.glob(baseImageDir + \"/*\"))\n",
    "    annot_list_all = sorted(glob.glob(baseAnnotDir + \"/*\"))\n",
    "\n",
    "    # Drop any images that doesnt have annotation (background)\n",
    "    # Or just leave it at some percentage of the dataset\n",
    "    backgroundImages_Percentage = 0.1\n",
    "    image_list = []\n",
    "    annot_list = []\n",
    "    \n",
    "    dataset_length_all = len(image_list_all)\n",
    "    max_background_image = int(dataset_length_all*backgroundImages_Percentage)\n",
    "    _counter = 0\n",
    "\n",
    "    for i in range(len(annot_list_all)):\n",
    "        \n",
    "        with open(annot_list_all[i]) as f:\n",
    "            _annot = f.read()\n",
    "\n",
    "            # Annotation not empty\n",
    "            if _annot:\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "            elif _counter < max_background_image:\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "                _counter = _counter + 1\n",
    "                \n",
    "    # Dataset length\n",
    "    dataset_length = len(image_list)\n",
    "    # print(dataset_length, len(annot_list))\n",
    "\n",
    "    split_ratio = 0.9\n",
    "    middle_point = round(split_ratio * dataset_length)\n",
    "\n",
    "    # Create random list number using seed\n",
    "    numberList = list(range(0, dataset_length))\n",
    "    random.shuffle(numberList)\n",
    "    trainNumberList = numberList[:middle_point]\n",
    "    validNumberList = numberList[middle_point:]\n",
    "    print(\"Training/Validation Samples :\", len(trainNumberList), len(validNumberList))\n",
    "\n",
    "    # Training images and labels\n",
    "    print(\"Copying training images and labels for\", countryName)\n",
    "    for i in tqdm(trainNumberList):\n",
    "\n",
    "        # Images\n",
    "        outputImagesDir = baseOutputDir + countryName + \"/images/train/\"\n",
    "        if not os.path.exists(outputImagesDir):\n",
    "            os.makedirs(outputImagesDir)\n",
    "\n",
    "        shutil.copy2(image_list[i], outputImagesDir)\n",
    "\n",
    "        # Annotations\n",
    "        outputAnnotDir = baseOutputDir + countryName + \"/labels/train/\"\n",
    "        if not os.path.exists(outputAnnotDir):\n",
    "            os.makedirs(outputAnnotDir)\n",
    "\n",
    "        shutil.copy2(annot_list[i], outputAnnotDir)\n",
    "        # print(outputImagesDir, outputAnnotDir)\n",
    "\n",
    "    # Validation images and labels\n",
    "    print(\"Copying validation images and labels for\", countryName)\n",
    "    for i in tqdm(validNumberList):\n",
    "\n",
    "        # Images\n",
    "        outputImagesDir = baseOutputDir + countryName + \"/images/val/\"\n",
    "        if not os.path.exists(outputImagesDir):\n",
    "            os.makedirs(outputImagesDir)\n",
    "\n",
    "        shutil.copy2(image_list[i], outputImagesDir)\n",
    "\n",
    "        # Annotations\n",
    "        outputAnnotDir = baseOutputDir + countryName + \"/labels/val/\"\n",
    "        if not os.path.exists(outputAnnotDir):\n",
    "            os.makedirs(outputAnnotDir)\n",
    "\n",
    "        shutil.copy2(annot_list[i], outputAnnotDir)\n",
    "        # print(outputImagesDir, outputAnnotDir)\n",
    "\n",
    "# baseDir = \"../dataset/RDD2022/RDD2022_all_countries/Japan/train/\"\n",
    "# CopyDatasetSplit(baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 8055 895\n",
      "Copying training images and labels for Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8055/8055 [01:50<00:00, 72.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 895/895 [00:18<00:00, 49.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 3594 399\n",
      "Copying training images and labels for India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3594/3594 [01:25<00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [00:09<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 1943 216\n",
      "Copying training images and labels for China_Drone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1943/1943 [00:39<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for China_Drone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:04<00:00, 49.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 1779 198\n",
      "Copying training images and labels for China_MotorBike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1779/1779 [00:37<00:00, 46.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for China_MotorBike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:03<00:00, 55.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Base Directory\n",
    "ROOTDIR = os.path.join(current_dir, \"dataset\", \"RDD2022\")\n",
    "\n",
    "# Use only japan india\n",
    "CountryListDir = [\"/RDD2022_all_countries/Japan/train/\",\n",
    "                  \"/RDD2022_all_countries/India/train/\",\n",
    "                  \"/RDD2022_all_countries/China_Drone/train/\",\n",
    "                  \"/RDD2022_all_countries/China_MotorBike/train/\",\n",
    "                #   \"/RDD2022/RDD2022_all_countries/Czech/train/\",\n",
    "                #   \"/RDD2022/RDD2022_all_countries/Norway/Norway/train/\",\n",
    "                #   \"/RDD2022/RDD2022_all_countries/United_States/United_States/train/\",\n",
    "]\n",
    "\n",
    "for CountryDir in CountryListDir:\n",
    "    CountryDir = ROOTDIR + CountryDir\n",
    "    CopyDatasetSplit(CountryDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume D\n",
      "Volume serial number is 146B-D5EC\n",
      "D:\\CODE\\CS632_ROADDAMAGEDETECTION\n",
      "\\---dataset\n",
      "    +---RDD2022\n",
      "    |   \\---RDD2022_all_countries\n",
      "    |       +---China_Drone\n",
      "    |       |   \\---train\n",
      "    |       |       +---annotations\n",
      "    |       |       |   \\---xmls\n",
      "    |       |       +---images\n",
      "    |       |       \\---labels\n",
      "    |       +---China_MotorBike\n",
      "    |       |   +---test\n",
      "    |       |   |   \\---images\n",
      "    |       |   \\---train\n",
      "    |       |       +---annotations\n",
      "    |       |       |   \\---xmls\n",
      "    |       |       +---images\n",
      "    |       |       \\---labels\n",
      "    |       +---India\n",
      "    |       |   +---test\n",
      "    |       |   |   \\---images\n",
      "    |       |   \\---train\n",
      "    |       |       +---annotations\n",
      "    |       |       |   \\---xmls\n",
      "    |       |       +---images\n",
      "    |       |       \\---labels\n",
      "    |       \\---Japan\n",
      "    |           +---test\n",
      "    |           |   \\---images\n",
      "    |           \\---train\n",
      "    |               +---annotations\n",
      "    |               |   \\---xmls\n",
      "    |               +---images\n",
      "    |               \\---labels\n",
      "    \\---rddJapanIndiaChinaFiltered\n",
      "        +---China_Drone\n",
      "        |   +---images\n",
      "        |   |   +---train\n",
      "        |   |   \\---val\n",
      "        |   \\---labels\n",
      "        |       +---train\n",
      "        |       \\---val\n",
      "        +---China_MotorBike\n",
      "        |   +---images\n",
      "        |   |   +---train\n",
      "        |   |   \\---val\n",
      "        |   \\---labels\n",
      "        |       +---train\n",
      "        |       \\---val\n",
      "        +---India\n",
      "        |   +---images\n",
      "        |   |   +---train\n",
      "        |   |   \\---val\n",
      "        |   \\---labels\n",
      "        |       +---train\n",
      "        |       \\---val\n",
      "        \\---Japan\n",
      "            +---images\n",
      "            |   +---train\n",
      "            |   \\---val\n",
      "            \\---labels\n",
      "                +---train\n",
      "                \\---val\n"
     ]
    }
   ],
   "source": [
    "!tree . /A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
